\chapter{Distributed Computing via Combinatorial Topology}
\label{ch2}
Based on the combinatorial description of (sufficiently well-behaved)
topological spaces by simplicial complexes we can define and (briefly) explain
our model for \emph{distributed tasks} and \emph{protocols that solve tasks}.
We give the strict mathematical definitions first and explain their
interpretation in the context of distributed computing afterwards.

\section{Mathematical Framework}
The following definitions rely on an additional type of map operating on
simplicial complexes that is more flexible than simplicial maps:

\begin{thDef}[carrier map]
    \label{ch2:def:carriermap}
    %
    Let $K,L$ be simplicial complexes. 
    \begin{itemize}
        \item
            A \emph{carrier map $\Phi\colon K\to L$} is a monotonic map
            \[ \Phi\colon K \to \{ L' \Mid L'\subset L \text{ is a subcomplex} \}  , \]
            where both sets are partially ordered by inclusion. More explicitly:
            For simplicies $F' \subset F$ in $K$ we require $\Phi(F') \subset
            \Phi(F)$ as subcomplexes of~$L$.
            
        \item
            Let $\Phi\colon K\to L$ be a carrier map. Then $\Phi$ is
            \emph{strict} if it satisfies
            \[ \Phi(F\cap F') = \Phi(F) \cap \Phi(F') \]
            for all simplices $F,F'\in K$.
            
\pagebreak[2]
        \item
            For $A\subset K$ the subcomplex
            \[ \Phi[A] \defeq \bigcup \Phi(A) \]
            of~$L$ is the \emph{image complex of $A$ under $\Phi$}
            and we call $\Phi[K]$ simply \emph{image complex of~$\Phi$}.
            
        \item
            Let $\Psi\colon L\to M$ be another carrier map. Then the
            \emph{composition of $\Phi$ and $\Psi$} is defined by
            \[ (\Psi\after\Phi)(F) \defeq \Psi[\Phi(F)] \]
            for all $F\in K$ (which is a carrier map $K\to M$).
    \end{itemize}
\end{thDef}

Note: While we say \enquote{carrier map $K\to L$}, the codomain of a carrier map
is \emph{not} actually~$L$ (but the set of subcomplexes of the latter).

\begin{ExampleList}[\label{ch2:ex:carriermaps}%
    See \cref{ch2:fig:carriermaps} for graphical representations of the
    following examples.%
    ]
    \item
        Let
        \begin{align*}
            L \defeq \bigl\{ &\{0,2,3\},\,
                \{0,1\},\, \{1,2\},\, \{0,3\},\, \{2,3\},\, \{2,4\},\,
                \\
                &\{0\},\, \{1\},\, \{2\},\, \{3\},\, \{4\},\,
                \emptyset
            \bigr\}
        \end{align*}
        and let
        \[ K \defeq L\bigl(\bigl\{ \{0,1\},\, \{1,2\},\, \{0,3\},\, \{2,3\}
                \bigr\}\bigr)
        . \]
        Let
        \[ \Phi_1(F) \defeq L(F) \]
        for all $F\in K\setminus\bigl\{ \{0,3\} \bigr\}$ and let
        \[ \Phi_1(\{0,3\}) \defeq L(\{0,2,3\}) . \]
        Then $\Phi_1$ is a carrier map $K\to L$. It is \emph{not} strict
        because
        \[ \Phi_1\bigl(\{0,3\} \cap \{2,3\}\bigr) = L(\{3\}) 
            \subsetneq L(\{2,3\}) = \Phi_1(\{0,3\}) \cap \Phi_1(\{2,3\})
        . \]
        The image complex of $\Phi_1$ is
        \[ \Phi_1[K] = L \setminus \bigl\{ \{2,4\}, \{4\} \bigr\}  . \]
        
    \item
        Let
        \[ \Phi_2(F) \defeq \Delta^2(F) \]
        for all $F\in\Delta^2\setminus\bigl\{\{1\}\bigr\}$ and let
        \[ \Phi_2(\{1\}) \defeq \Delta^2 . \]
        Then $\Phi_2$ is \emph{not} a carrier map $\Delta^2\to\Delta^2$
        because is is not monotonic: we have
        \[ \Phi_2(\{1\}) = \Delta^2
            \not\subset \Delta^2(\{0,1\}) = \Phi_2(\{0,1\}) \]
        although $\{1\} \subset \{0,1\}$.
        
    \item\label{ch2:ex:carriermaps:lat}
        Let $T$ be the complex from \cref{ch2:fig:carriermaps};
        it is well known that it triangulates the torus~$S^1\times S^1$.
        We define $\Phi_3\colon\Delta^2\to T$ as follows:
        \begin{align*}
              \emptyset &\mapsto \{\emptyset\}
            & \{0,1\} &\mapsto T(\{3,5\})
              \\
              \{0\}   &\mapsto T(\{3\})
            & \{1,2\} &\mapsto T(\{\{5,9\}, \{9,1\}\})
              \\
              \{1\}   &\mapsto T(\{5\})
            & \{0,2\} &\mapsto T(\{1,3\})
              \\
              \{2\}   &\mapsto T(\{1\})
            & \{0,1,2\} &\mapsto T
        \rlap{.}
        \end{align*}
        It is easy to see that $\Phi_3$ is indeed a carrier map,
        that it is strict and that its image complex is~$T$.
\end{ExampleList}

\begin{figure}
    \centering
    \newcommand{\mar}{10pt}
    \newcommand{\labelL}{-1.75cm}
    \newcommand{\labelR}{11.5cm}
    %
    \begin{tikzpicture}
        \colorlet{COne}{green!30!blue}
        %
        \begin{scope}[yshift=10cm]
            \begin{scope}
                \path
                    (0,0) node [Svertex] {}
                    (2,0) node [Svertex] {}
                    (2,2) node [Svertex] {} 
                    (0,2) node [Svertex] {} ;
                \draw [Sedge] (0,0) -- (2,0) -- (2,2) -- (0,2) ;
                \draw [Sedge=COne] (0,0) -- (0,2) ;
                \draw (0,0) -- (2,0) -- (2,2) -- (0,2) -- cycle ;
                \path
                    (0,0) node [Dpoint] {} +(-\mar,0) node {$0$}  
                    (2,0) node [Dpoint] {} +(\mar,0)  node {$1$}  
                    (2,2) node [Dpoint] {} +(\mar, 0) node {$2$} 
                    (0,2) node [Dpoint] {} +(-\mar,0) node {$3$} ;
            \end{scope}
            %
            \draw [->, line width=0.8pt]
                (3.6,1) -- node [above] {$\Phi_1$} (5,1) ;
            %
            \begin{scope}[xshift=7.4cm]
                \newcommand{\mypath}{%
                    (0,0) -- (2,0) -- (2,2) -- (0,2) -- cycle}
                \path
                    (0,0) node [Svertex] {}
                    (2,0) node [Svertex] {}
                    (2,2) node [Svertex] {} 
                    (0,2) node [Svertex] {} ;
                \draw [Sedge] (0,0) -- (2,0) -- (2,2) -- (0,2) ;
                \draw [Sedge=COne] (0,0) -- (0,2) ;
                \fill [Dfill] (0,0) -- (2,2) -- (0,2) -- cycle ;
                \pattern [pattern color=COne, pattern=my north west lines]
                    (0,0) -- (2,2) -- (0,2) -- cycle ;
                \draw \mypath 
                      (0,0) -- (2,2) -- (2.5,1) ;
                \path
                    (0,0)   node [Dpoint] {} +(-\mar,0) node {$0$} 
                    (2,0)   node [Dpoint] {} +(\mar, 0) node {$1$}
                    (2,2)   node [Dpoint] {} +(\mar, 0) node {$2$}
                    (0,2)   node [Dpoint] {} +(-\mar,0) node {$3$}
                    (2.5,1) node [Dpoint] {} +(\mar, 0) node {$4$} ;
            \end{scope}
            %
            \path
                (\labelL,1) node {$K$}
                (\labelR,1) node {$L$} ;
        \end{scope}
        %
        %
        \begin{scope}[yshift=5cm]
            \begin{scope}[yshift=15pt]
                \newcommand{\mypath}{%
                    (0,0) -- (2,0) -- (60:2) -- cycle}
                \path
                    (0,0)  node [Svertex] {}
                    (60:2) node [Svertex] {} ;
                \draw [Sedge] \mypath ;
                \fill [Dfill] \mypath ;
                \path
                    (2,0)  node [Svertex=COne] {} ;
                \draw \mypath ;
                \path
                    (0,0)  node [Dpoint] {} +(0,-\mar) node {$0$}  
                    (2,0)  node [Dpoint] {} +(0,-\mar) node {$1$}  
                    (60:2) node [Dpoint] {} +(0,\mar)  node {$2$} ;
            \end{scope}
            %
            \draw [->, line width=0.8pt]
                (3.6,1.5) -- node [above] {$\Phi_2$} (5,1.5) ;
            %
            \begin{scope}[xshift=7.4cm,yshift=15pt]
                \newcommand{\mypath}{%
                    (0,0) -- (2,0) -- (60:2) -- cycle}
                \path
                    (0,0)  node [Svertex] {}
                    (60:2) node [Svertex] {} ;
                \draw [Sedge] \mypath ;
                \fill [Dfill] \mypath ;
                \pattern [pattern color=COne, pattern=my north west lines]
                    \mypath ;
                \path
                    (2,0)  node [Svertex=COne] {} ;
                \draw \mypath ;
                \path
                    (0,0)  node [Dpoint] {} +(0,-\mar) node {$0$}  
                    (2,0)  node [Dpoint] {} +(0,-\mar) node {$1$}  
                    (60:2) node [Dpoint] {} +(0,\mar)  node {$2$} ;
            \end{scope}
            %
            \path
                (\labelL,1.5) node {$\Delta^2$}
                (\labelR,1.5) node {$\Delta^2$} ;
        \end{scope}
        %
        %
        \begin{scope}
            \begin{scope}[yshift=15pt]
                \newcommand{\mypath}{%
                    (0,0) -- (2,0) -- (60:2) -- cycle}
                \path
                    (0,0)  node [Svertex] {}
                    (2,0)  node [Svertex] {}
                    (60:2) node [Svertex] {} ;
                \draw [Sedge] \mypath ;
                \fill [Dfill] \mypath ;
                \draw \mypath ;
                \path
                    (0,0)  node [Dpoint] {} +(0,-\mar) node {$0$}  
                    (2,0)  node [Dpoint] {} +(0,-\mar) node {$1$}  
                    (60:2) node [Dpoint] {} +(0,\mar)  node {$2$} ;
            \end{scope}
            %
            \draw [->, line width=0.8pt] (3.6,1.5) -- node [above] {$\Phi_3$} (5,1.5) ;
            %
            \begin{scope}[xshift=7cm]
                \foreach \coord in {(2,0),(3,1),(3,3),(2,3)}
                    \path \coord node [Svertex] {} ;
                %
                \path [Sedge]
                    (2,0) -- (3,1) -- (3,3) -- (2,3) ;
                %
                \foreach \myx in {0,1,2} {
                    \foreach \myy in {0,1,2} {
                        \begin{scope}[shift={(\myx,\myy)}]
                            \path [Dfill] (0,0) rectangle (1,1);
                            \draw (0,0) -- (1,0) -- (1,1) ;
                            \draw (0,0) -- (1,1) -- (0,1) -- cycle ;
                            \foreach \coord in {(0,0),(0,1),(1,0),(1,1)}
                                \node [Dpoint] at \coord {};
                        \end{scope}
                    }
                }
                %
                \foreach \coord/\k in {(0,0)/1,(1,0)/2,(2,0)/3,(3,0)/1}
                    \path \coord ++(0,-\mar) node {$\k$} 
                          \coord ++(0,3) ++(0,\mar) node {$\k$} ;
                %
                \foreach \coord/\k in {(0,1)/5,(0,2)/9}
                    \path \coord ++(-\mar,0) node {$\k$}
                          \coord ++(3,0) ++(\mar,0) node {$\k$} ;
            \end{scope}
            %
            \path
                (\labelL,1.5) node {$\Delta^2$}
                (\labelR,1.5) node {$T$} ;
        \end{scope}
        %
    \end{tikzpicture}
    %
    \vspace{0.5cm}
    %
    \caption{Examples of carrier maps, see also \cref{ch2:ex:carriermaps}.}
    \label{ch2:fig:carriermaps}
\end{figure}

In addition to the composition of carrier maps we can also define how to compose
carrier maps with simplicial maps from both sides. To do that properly, we need

\begin{thDef}[image complex under a simplicial map]
    For a simplicial map $f\colon K\to L$ and a subcomplex $K'$ of
    $K$ we call the subcomplex
    \[ f[K'] \defeq \{ f(F) \Mid F\in K' \} \]
    of~$L$ the \emph{image complex of $K'$ under $f$}.
\end{thDef}

\begin{thDef}[composition of carrier maps with simplicial maps]
    Let $\Phi\colon K_2\to K_3$ be a carrier map and let
    $f\colon K_1\to K_2$ and $g\colon K_3\to K_4$ be simplicial
    maps. We define the carrier maps
    $\Phi\after f\colon K_1\to K_3$ and $g\after\Phi\colon K_2\to K_4$
    as follows:
    \[ (\Phi\after f)(F) \defeq \Phi(f(F))
        \qandq
        (g\after \Phi)(F') \defeq g[\Phi(F')]
    \]
    for all $F\in K_1$, $F'\in K_2$.
\end{thDef}

We are now ready to define our main objects of interest, namely \emph{tasks}
and \emph{protocols} as well as the concept of \emph{task solving}.

\begin{thDef}[task and protocol]
    \label{ch2:def:taskprotocol}
    %
    Let $\cI,\cO,\cP$ be simplicial complexes.
    \begin{itemize}
        \item
            A \emph{task} is a carrier map $\Phi\colon\cI\to\cO$.
            We call $\cI$ and $\cO$ the \emph{input} and \emph{output complex},
            respectively.
            
        \item
            A \emph{protocol} is a strict carrier map $\Xi\colon\cI\to\cP$
            where $\cP$ is the image complex of~$\Xi$.
            We call $\cI$ and $\cP$ the \emph{input} and \emph{protocol
            complex}, respectively.
    \end{itemize}
\end{thDef}

\begin{thConvention}[the $(-1)$-simplex]
    Our definition of a simplicial complex ensures that it always includes the
    $(-1)$-simplex (i.\,e. the empty simplex) whenever the complex is not empty
    itself. In the context of tasks and protocols, however, the empty simplex
    does not have a useful interpretation (see the next section). Therefore, we
    employ the following rules for dealing with the $(-1)$-simplex.
    \begin{itemize}
        \item
            Unless mentioned otherwise, a task $\Phi\colon\cI\to\cO$ always
            maps the empty simplex to the subcomplex of~$\cO$ containing only
            the empty simplex (i.\,e. $\Phi(\emptyset) = \{\emptyset\}$).
            
        \item
            The same rule applies mutatis mutandis to protocols.
            
        \item
            When we describe tasks or protocols, we occasionally ignore the
            $(-1)$-simplex as part of some or all complexes. For instance,
            we might write something like $\Phi(F) = \{\{x\}\}$ whereas
            it had to be $\Phi(F) = \{\emptyset,\{x\}\}$ for the
            latter to be a proper simplicial complex. The effect of
            this rule is a clearer notation without any actual loss
            of information. (Note, that this is only a simplification
            in writing and that the complexes, of course, still contain
            the $(-1)$-simplex.)
    \end{itemize}
\end{thConvention}

\begin{thDef}[task solving]
    Let $\cI,\cO$ and $\cP$ be simplicial complexes,
    let $\Phi\colon\cI\to\cO$ be a task,
    and let $\Xi\colon\cI\to\cP$ be a protocol.
    Then \emph{$\Xi$ solves $\Phi$} if there exists a simplicial map
    \[ \delta\colon\cP\to\cO \] 
    such that $\delta\after\Xi$ \emph{is carried by $\Phi$},
    which means that
    \[ (\delta\after\Xi)(F) \subset \Phi(F) \]
    as subcomplexes of $\cO$ is satisfied for all $F\in\cI$.
    Such a map $\delta$ is called a \emph{decision map}.
\end{thDef}

\section{Interpretation of the Model}
It is about time that we explain some of the definitions of the previous
section in the context of our headline \emph{distributed computing}.
We start with an example:

\begin{thExample}[consensus]
    \label{ch2:consensus}
    %
    Let $X$ be a finite set of cardinality~$p$.
    Suppose we have a system with a number of processes, each with an initial
    private \enquote{piece of information} which we require to be an element
    of~$X$. (The input values need not be distinct.) Now the processes may
    communicate (subject to certain constrains of the considered system) and
    finally have to \enquote{decide} on exactly one of the input values. That is
    all processes halt with a private output value and all of these values have
    to be the same (and additionally one of the input values). For obvious
    reasons, this task is called \emph{$p$-consensus}. Note that we are only
    interested in the set of assigned input values and the (in this example
    singleton) set of private output values.
    
    Now we explain what the corresponding input and output complexes are:
    The input complex encodes every possible \emph{input configuration},
    that is, $F$ is a simplex of~$\cI$ in this case if and only if
    $F\subset X$. (At this point, we should assume that there are more
    processes than input values because an input configuration with more
    values than processes does not make much sense.)
    The output complex encodes
    every allowed \emph{output configuration}, that is, $F'\in\cO$ if and only
    if $F'\subset X$ is a singleton set. The carrier map~$\Phi$ then encodes
    which input configurations may lead to which output configurations:
    If all processes start with $x\in X$, the only allowed output configuration
    is $\{x\}$, so $\Phi(\{x\})$ would be $\{\{x\}\}$. If the input configuration
    is $\{x,y\}$ (with $x\neq y$), the processes may either choose $x$ or $y$
    as their consensus, so $\Phi(\{x,y\})$ is $\{ \{x\}, \{y\} \}$. In general:
    \[ \Phi(F) = \bigl\{ \{t\} \Mid t\in F \bigr\}  . \]
    It is readily verified that $\Phi\colon\cI\to\cO$ is a task in the sense
    of~\cref{ch2:def:taskprotocol}. Observe that $\cI$ is isomorphic to (the
    complex obtained from) the standard simplex~$\Delta^{p-1}$ and $\cO$
    is its $0$-skeleton.
\end{thExample}

This example easily generalizes to other tasks:
the complex $\cI$~always encodes the possible input configurations,
$\cO$~represents valid output configurations and $\Phi\colon\cI\to\cO$
specifies the actual task, that is for each input configuration it
specifies the set of output configurations that are considered a
\enquote{successful completion of the task} according to the task's
description.

A protocol $\Xi\colon\cI\to\cP$ permits a similar interpretation:
Again, every simplex in $\cI$ is a possible input configuration to
the system of processes. Then these processes run some sort of
(communication) algorithm whose possible output configurations are
captured by $\Xi$ and $\cP$. That means if $F\in\cI$ is an input
configuration, $\Xi(F) \subset \cP$ includes every possible output
configuration that may arise from the input configuration~$F$ and
one execution of the specified algorithm. Note, that in this case
an \enquote{algorithm} is not entirely deterministic (in the sense
that we cannot predict the exact ouput configuration) because the
communication between processes introduces a degree of uncertainty.
As mentioned in the introduction, this corresponds to the fact that
we model protocols that are \emph{wait-free}.

Finally, if $\Xi$ solves $\Phi$ and $\delta\colon\cP\to\cO$ is a decision
map, $\delta$ is, intuitively speaking, the \enquote{function that
gets applied to a process's (protocol) output value to produce a valid
task output value}. The protocol output value represents
\enquote{everything a process has learned} during the communication
and the map~$\delta$ \enquote{decides which task output value to
choose based on that information}, hence the name \emph{decision map}.

We should note that the simplicial properties of $\cI$, $\cO$, $\cP$
or the maps $\Phi$, $\Xi$, $\delta$ were not used in our informal
description so far, so it is natural to ask why we chose simplicial
complexes as a mathematical basis. Simply put, those properties are
related to the various assumptions about the underlying distributed
system. For example, an input complex~$\cI$ has to be a simplicial 
complex because a process could crash before communicating its input
value to the other processes: An input configuration $F\in\cI$
should contain all values that are actually used by any of
the processes to produce an output value. Now let $F'\subset F$ and
assume that the processes with input values in $F\setminus F'$ crash
before sending their values to any of the other processes. Then the
latter continue their execution \emph{with values from~$F'$ only}, so
the true input configuration has to be~$F'\subset F$. Put another way,
$\cI$ must contain all subsets of all elements $F\in\cI$, which is
precisely the definition of a simplicial complex.

There is much more that could be said about the \enquote{simplicial
assumptions} of our model but in this thesis we will not go into much more
detail. However, there is an extensive discussion of the
correspondence between the above \enquote{combinatorial model} and the
\enquote{operational model} (which describes tasks and protocols from
a computer scientist's point of view) in the book by
Herlihy et~al.~\cite[Ch.\,4]{bookc:herlihyetal13}.

\vfill % !!! layout hack


\section[Examples: Set Agreement and Barycentric Agreement]{%
         Examples:\newline Set Agreement and Barycentric Agreement}
Next, we are going to describe another class of examples, relaxed versions of
the consensus task \pcref{ch2:consensus}, one of which will play an important
role in \cref{ch2:sec:consequences}.

\begin{thExample}[set agreement]
    \label{ch2:setagreement}
    %
    Let $X$ be a finite set of cardinality~$p$ and assume there are
    $n$~processes where $n\geq p$.  The \emph{$p$-values $k$-set
    agreement task} (or \emph{$(p,k)$-set agreement} for short) is
    defined by the following task description:
    Each process's input value is an element of~$X$ (where different
    processes may be assigned the same input value) and each process's
    output value is one of the assigned input values such that
    the output configuration (set of all chosen output values)
    is a subset of~$X$ of cardinality at most~$k$. Put another way,
    the task requires the processes to choose at most $k$ distinct
    output values (from the set of input values).
    
    An analogous analysis as in \cref{ch2:consensus} shows, that
    the formal task (in the sense of \cref{ch2:def:taskprotocol})
    is given by the input complex~$\Delta^{p-1}$, the output complex
    $(\Delta^{p-1})^{\leq k-1}$ and the following carrier map~$\skel^{k-1}$:
    if $F\in\Delta^{p-1}$ is an input configuration, $\skel^{k-1}(F)$ is the
    $(k{-}1)$-skeleton of the complex determined by $F$:
    \[ \skel^{k-1}(F) \defeq \bigl(\Delta^{p-1}(F)\bigr)^{\leq k-1}
    ; \]
    this obviously defines a carrier map. (To keep the notation
    readable we write only $\skel^{k-1}$ even though the carrier map,
    of course, also depends on~$p$.)
    
    A few notes:
    \begin{itemize}
        \item
            Whereas the task description assumes that sufficiently many
            processes are involved, the number of processes~$n$ is completely
            irrelevant for the formal definition of $(p,k)$-set agreement
            as the task
            $\skel^{k-1}\colon\Delta^{p-1}\to(\Delta^{p-1})^{\leq k-1}$.
            
        \item
            For $k=1$, we see that $(p,1)$-set agreement coincides with
            $p$-consensus \pcref{ch2:consensus}.
            
        \item
            If $p\leq k$, the task is trivial because every process can simply
            choose its input value. Formally: Since $p\leq k$ we have
            $(\Delta^{p-1})^{\leq k-1} = \Delta^{p-1}$ and the carrier map
            $\skel^{k-1}$ assigns to a simplex the complex determined by all its
            faces. Furthermore $\skel^{k-1}$ is strict, as one may easily check.
            (With essentially the same arguments, the last assertion also holds
            in the general case where $p > k$.) So the task
            $\skel^{k-1}\colon\Delta^{p-1}\to\Delta^{p-1}$ is solved by
            $\skel^{k-1}$ (viewed as a protocol) with the identity map
            on $V(\Delta^{p-1})$ as decision map.
    \end{itemize}
\end{thExample}

Another important class of examples are \emph{barycentric agreement tasks}. To
state them formally, we first need to recognize $\sd$ \pcref{ch1:def:sd}
as a carrier map:

\vfill % !!! layout hack

\pagebreak[2]\noindent
Let $K$ be a simplicial complex. For a simplex~$F$ of~$K$ we define
$\sd_K(F) \defeq \sd K(F)$ which is a subcomplex of~$\sd K$. Thus we
obtain a carrier map $\sd_K\colon K\to\sd K$. Since we can compose
$\sd_K$ with $\sd_{\sd K}$ and so on, we also obtain a carrier map
$K\to\sd^N\!K$ for all $N\in\N$ which we denote by $\sd_K^N$.

\begin{thExample}[barycentric agreement]
    \label{ch2:barycentricagreement}
    %
    \;Let $K$ be a simplicial complex and let~$N\in\N$. The
    \emph{$N$-th barycentric agreement task for the input complex~$K$}
    is the task $\sd_K^N\colon K\to\sd^N K$.
    
    In other words, the processes are assigned vertices of some simplex~$F$
    of~$K$ and the task is to decide on vertices of a simplex
    of~$\sd_K^N(F)$, the $N$-th barycentric subdivision of~$F$
    (as a subcomplex of $\sd^N K$).
\end{thExample}

Also note that for all $K\in\Simp$ and all $N\in\N$ the carrier map
$\sd_K^N$ is strict and \enquote{surjective} (in the sense of the image
complex). Therefore $\sd_K^N$ is also a protocol which we denote by
the same symbol (there is no actual danger of confusion).


\section{Implements-Relation on Tasks}
Informally, it is relatively clear what it means that some tasks implement
(or rather can be used to implement) another task. This section will make
that intuition formal in an appropriate sense.

In \cref{ch2:def:carriermap} we saw how to compose carrier maps,
which naturally applies to tasks (because a task is just a carrier
map). Since we would also like to compose protocols we prove the following

\begin{thLemma}[composition of strict carrier maps]
    Let $K,L,M$ be simplicial complexes and let $\Phi\colon K\to L$
    and $\Psi\colon L\to M$ be strict carrier maps.
    Then their composition $\Psi\after\Phi\colon K\to M$ is strict as well.
\end{thLemma}

\begin{proof}
    Let $F$ and $F'$ be simplices of~$K$. We have to show that
    \[ (\Psi\after\Phi)(F\cap F')
        = (\Psi\after\Phi)(F) \cap (\Psi\after\Phi)(F')
    . \]
    By definition of $\Psi\after\Phi$, basic set theory and strictness
    of~$\Psi$ we obtain:
    \begin{align*}
    (\Psi\after\Phi)(F) \cap (\Psi\after\Phi)(F')
        \,&=
        \Bigl( \mkern2mu \bigcup_{G\in\mathrlap{\Phi(F)}} \, \Psi(G) \Bigr)
            \cap \Bigl( \bigcup_{G'\in\mathrlap{\Phi(F')}} \, \Psi(G') \Bigr)
            \\[5pt]
        &=
        \bigcup_{G\in\Phi(F)} \; \bigcup_{G'\in\Phi(F')}
            \Psi(G\cap G')
    . \end{align*}
    Since $\Phi(F)$ and $\Phi(F')$ are subcomplexes of~$L$, they contain every
    face of $G\in\Phi(F)$ and $G'\in\Phi(F')$, respectively. In particular,
    $G\cap G'$ is already a simplex of $\Phi(F)\cap\Phi(F')$, which shows the
    non-trivial inclusion of the following equality:
\pagebreak[2]
    \[ \bigcup_{G\in\Phi(F)} \; \bigcup_{G'\in\Phi(F')} \Psi(G\cap G')
        \quad\surround{\mkern2mu}{=}
        \bigcup_{\tilde G\in\Phi(F)\cap \Phi(F')} \Psi(\tilde G)
    . \]
    By strictness of~$\Phi$ and the definition of $\Psi\after\Phi$ the right
    hand side is equal to $(\Psi\after\Phi)(F\cap F')$.
    \\
\end{proof}

\begin{thCorollary}[composition of protocols]
    Let $\cI,\cP,\cI',\cP'$ be simplicial complexes with~$\cP\subset\cI'$,
    and let $\Xi\colon\cI\to\cP$ and $\Xi'\colon\cI'\to\cP'$ be protocols.
    Then the composition~$\Xi'\after\Xi$ is again
    a protocol onto its image complex $(\Xi'\after\Xi)[\cI]$.
\end{thCorollary}

Generally, we want to formalize the following situation: suppose we are
given a set of tasks~$T$ and for each $\Phi\in T$ a protocol that
solves $\Phi$, can we use these protocols to to solve another task~$\Phi'$? If
this is the case, we say \emph{the tasks of $T$ implement $\Phi'$}.

In this thesis, however, we only need a restriced version of this concept.
First of all, when we talk about whether some \emph{task implements another},
we always assume that the set of solved tasks includes the barycentric agreement
tasks \pcref{ch2:barycentricagreement} for all~$N\in\N$ and all occurring
complexes. Secondly, we only consider the case where the first task's carrier map
is strict, which means it \enquote{solves itself as a protocol} (like in the
$(p\mkern1mu{\leq}\mkern1muk)$-case of \cref{ch2:setagreement}). And lastly, we
only allow a specific amount and order of protocols used. Put formally, this
becomes:

\begin{thDef}[task implementing a task]
    Let $\cI,\cO,\cO'$ be simplicial complexes, let
    $\Phi\colon\cI\to\cO$ and $\Phi'\colon\cI\to\cO'$ be tasks, and
    let the carrier map of $\Phi$ be strict (so that we can consider $\Phi$ as a
    protocol onto its image complex). Then \emph{the task~$\Phi$ implements the
    task~$\Phi'$} if there exists an $N\in\N$ such that $\sd_{\cI}^N\after\Phi$,
    the composition of a barycentric agreement protocol
    $\sd_{\cI}^N\colon\cI\to\sd^N\cI$ and~$\Phi$, solves~$\Phi'$.
\end{thDef}

We will see later that this is enough for our purposes. We also note that the
assumption of available barycentric agreement protocols is not absurd, on
the contrary: Herlihy et~al.~\cite[Corollary 4.2.10]{bookc:herlihyetal13} show
that our underlying computational model permits an (operational) implementation
of those protocols and even better, that they can be obtained directly from 
\emph{immediate snapshot protocols} (mentioned in the introduction).
